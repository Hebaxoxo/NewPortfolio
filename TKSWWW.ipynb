{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Answer              emotions  \\\n",
      "0     My family was the most salient part of my day,...   anxious,happy,proud   \n",
      "1     Yoga keeps me focused. I am able to take some ...                  calm   \n",
      "2     Yesterday, my family and I played a bunch of b...  calm,happy,satisfied   \n",
      "3     Yesterday, I visited my parents and had dinner...            calm,happy   \n",
      "4     Yesterday, I really felt the importance of my ...                 happy   \n",
      "...                                                 ...                   ...   \n",
      "1468  A workout, dining with friends makes for a hea...       happy,satisfied   \n",
      "1469  My connection to God, through prayer brings me...            calm,happy   \n",
      "1470  I got a skull pan for halloween, and my husban...           happy,proud   \n",
      "1471  I spoke over the phone with my brother that li...                 happy   \n",
      "1472  I had a lengthy but mostly fun, frivolous conv...        calm,satisfied   \n",
      "\n",
      "        topics  \n",
      "0       family  \n",
      "1     exercise  \n",
      "2       family  \n",
      "3       family  \n",
      "4       health  \n",
      "...        ...  \n",
      "1468    health  \n",
      "1469       god  \n",
      "1470      food  \n",
      "1471    family  \n",
      "1472      love  \n",
      "\n",
      "[1473 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Create empty lists for emotions and topics\n",
    "emotions = []\n",
    "topics = []\n",
    "\n",
    "# Process each row in the dataset\n",
    "for index, row in data.iterrows():\n",
    "    # Extract emotions from the row\n",
    "    row_emotions = [col.split('.')[2] for col, value in row.items() if value and col.startswith('Answer.f')]\n",
    "    emotions.append(','.join(row_emotions))\n",
    "\n",
    "    # Extract topics from the row\n",
    "    row_topics = [col.split('.')[2] for col, value in row.items() if value and col.startswith('Answer.t')]\n",
    "    topics.append(','.join(row_topics))\n",
    "\n",
    "\n",
    "# Add emotions and topics as new columns\n",
    "data['emotions'] = emotions\n",
    "data['topics'] = topics\n",
    "df = data[['Answer','emotions','topics']]\n",
    "# Save the updated dataset\n",
    "print(df)\n",
    "df.to_csv('real.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "\n",
    "# Load data from CSV\n",
    "data = pd.read_csv('journal_entries.csv')\n",
    "\n",
    "journal_entries = data['entry'].tolist()\n",
    "emotions = data['emotions'].apply(lambda x: x.split(',')).tolist()\n",
    "topics = data['topic'].tolist()\n",
    "\n",
    "# Tokenize and encode journal entries\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_entries = [tokenizer.encode(entry, add_special_tokens=True, max_length=128, truncation=True) for entry in journal_entries]\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = [[float(i > 0) for i in entry] for entry in tokenized_entries]\n",
    "\n",
    "# Encode emotions and topics as numerical labels\n",
    "label_map = {'anxious': 0, 'happy': 1, 'proud': 2, 'calm': 3, 'satisfied': 4, 'angry': 5, 'bored': 6, 'frustrated': 7, 'sad': 8}\n",
    "encoded_emotions = [label_map[emotion] for emotions_row in emotions for emotion in emotions_row]\n",
    "encoded_topics = [label_map[topic] for topic in topics]\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "input_ids = torch.tensor(tokenized_entries, dtype=torch.long)\n",
    "attention_masks = torch.tensor(attention_masks, dtype=torch.long)\n",
    "labels = torch.tensor(encoded_emotions, dtype=torch.long)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_inputs, val_inputs, train_masks, val_masks, train_labels, val_labels = train_test_split(\n",
    "    input_ids, attention_masks, labels, random_state=42, test_size=0.2\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 16\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Step 2: Model Training\n",
    "\n",
    "# Load the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
    "\n",
    "# Define the optimizer and learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, labels = batch\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=input_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print average training loss for the epoch\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1} - Average training loss: {avg_train_loss}\")\n",
    "\n",
    "# Step 3: Prediction\n",
    "\n",
    "# Evaluation on validation set\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    input_ids, input_mask, labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=input_mask)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.extend(logits)\n",
    "    true_labels.extend(label_ids)\n",
    "\n",
    "# Convert predictions and true labels to emotions\n",
    "predicted_emotions = [list(label_map.keys())[np.argmax(pred)] for pred in predictions]\n",
    "true_emotions = [list(label_map.keys())[label] for label in true_labels]\n",
    "\n",
    "# Print predicted emotions for each journal entry\n",
    "for entry, emotion in zip(journal_entries, predicted_emotions):\n",
    "    print(f\"Journal Entry: {entry}\")\n",
    "    print(f\"Predicted Emotion: {emotion}\")\n",
    "    print(\"--------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
